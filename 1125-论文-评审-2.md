

# **LibOrtho：通过几何隔离解耦通用智能与记忆化 —— 针对顶级会议最佳论文奖的综合性批判审查与整改报告**

## **1\. 执行摘要与评审决定**

论文标题：LibOrtho: 通过几何隔离解耦通用智能与记忆化——面向可信大语言模型推理的对偶流形架构  
审查角色：程序主席及跨学科领域主席（机器学习系统 / 可信人工智能方向）  
推荐决定：有条件录用并需重大修改（Conditional Accept with Major Revisions） —— 建议纳入最佳论文奖（Best Paper Award）候选培育计划  
在当前大语言模型（LLM）的研究版图中，模型性能（Utility）与隐私安全（Privacy）之间的张力已成为阻碍其在敏感领域部署的核心瓶颈。现有的解决方案，如差分隐私（Differential Privacy）或机器遗忘（Machine Unlearning），往往陷入“为了遗忘而牺牲智能”的零和博弈中。投稿论文《LibOrtho》提出了一种极具前瞻性的范式转移：从算法层面的“遗忘”转向架构层面的“隔离”。通过将模型权重在物理上解耦为承载“通用智能”的低精度密集流（Base Stream）和承载“隐私记忆”的高精度稀疏流（Orthogonal Stream），作者试图构建一种确定性的隐私控制机制。这种将量化误差重新解释为“隐私信号”而非“噪声”的视角，展现了极高的智力美感和系统设计巧思。

然而，作为旨在角逐顶级会议（如NeurIPS, ICLR, OSDI）最佳论文奖的候选作品，本文在理论严密性和评估标准上仍存在显著的缺陷，特别是未能充分回应2024年至2025年间该领域涌现的突破性成果。

首先，本文的核心理论假设——“记忆化对应于损失景观的高曲率方向”——与2025年Merullo等人发表的关于损失曲率谱的最新研究存在直接的理论冲突（即“Merullo悖论”）。最新的证据表明，在数据集的聚合视图下，记忆化往往表现为低曲率（平坦）方向，而通用推理能力则表现为高曲率（刚性）结构。这种视角的差异必须被严谨地调和，否则将动摇LibOrtho的理论根基。

其次，在评估维度上，本文主要依赖“Canary提取率”这一相对陈旧的指标。在2025年的安全审计标准下，仅防御逐字提取已无法满足要求。学术界已建立了包括TOFU（虚构遗忘任务）、WMDP（大规模杀伤性武器代理基准）和MUSE（六维遗忘评估）在内的新一代基准体系，这些基准不仅考察逐字记忆，还深入考察概率性泄漏（如成员推断攻击）和模型效用的保留情况。

本报告将提供一份长达15,000字的详尽分析，深入解构LibOrtho的几何假设、系统架构及安全边界。我们将结合最新的文献证据，为作者提供一条清晰的整改路线图，旨在帮助该工作从“优秀的系统论文”升格为“定义领域的奠基性工作”。

---

## **2\. 理论框架深析：记忆化的几何本质与谱分离悖论**

LibOrtho的理论大厦建立在\*\*定理1（记忆化的谱分离）\*\*之上，该定理试图在数学上证明通用知识与特定记忆在Hessian特征空间中的正交性。虽然这一推导在逻辑上自洽，但在面对2025年最新的深度学习理论进展时，其前提假设显露出脆弱性。本节将对这一理论框架进行深度的批判性重构。

### **2.1 核心假设的二元对立：LibOrtho vs. 2025前沿理论**

作者的核心假设是：LLM的权重存在于一个低维流形（$M\_{pub}$）上，代表通用智能；而隐私数据作为高频扰动（$\\Delta w$），存在于该流形的法向分量上，表现为高曲率的“异常值” 1。基于此，作者利用对角Hessian矩阵筛选出高曲率权重并将其隔离到稀疏流中。

#### **2.1.1 “Merullo悖论”：高曲率与低曲率的认知冲突**

在审查过程中，我们注意到这一假设与Merullo等人于2025年发表的重磅研究《From Memorization to Reasoning in the Spectrum of Loss Curvature》2 形成了尖锐的对立。

* **LibOrtho的视角**：记忆化样本是梯度的异常值，为了拟合这些异常点，模型必须在特定的权重方向上进行剧烈调整，导致局部损失景观极其陡峭（高曲率）。因此，剔除高曲率分量等于剔除记忆 1。  
* **Merullo等人的视角（2025）**：通过分析K-FAC（Kronecker-Factored Approximate Curvature）分解后的Fisher信息矩阵，研究发现“通用推理”能力（如逻辑推演、开放域问答）实际上依赖于**高曲率**的共享结构。这是因为这些结构被海量数据共同使用，任何微小的扰动都会导致全局损失剧烈上升（即“刚性”结构）。相反，纯粹的逐字记忆往往对应于**低曲率**（平坦）方向，因为这些方向仅与极少数训练样本相关，改变它们对全局平均损失的影响微乎其微 4。

这一冲突构成了本论文通往最佳论文奖的最大理论障碍：如果Merullo是正确的，即推理依赖高曲率而记忆依赖低曲率，那么LibOrtho基于高曲率筛选出的“正交流（Orthogonal Stream）”可能恰恰包含了核心的推理能力，而将真正的记忆化残留在了基础流中。

#### **2.1.2 悖论的消解：微观实例与宏观总体的对立统一**

为了挽救LibOrtho的理论有效性，作者必须在修改稿中明确界定“曲率”的定义域。我们认为，这两种看似矛盾的理论实际上描述了现象的不同侧面：

1. **实例级曲率（Instance-Level Curvature）与离群值**：LibOrtho关注的是**单个记忆化样本**对梯度的贡献。对于一个特定的、罕见的隐私数据点（如某人的身份证号），它在训练集中是一个离群值（Outlier）。为了强行拟合这个点，模型必须在某些权重上形成“尖刺”。相对于该**特定样本**的损失函数而言，这里的曲率是极高的。LibOrtho的筛选机制（$R\_{ij}=(w\_{ij}-q\_{ij})^{2}\\cdot H\_{jj}$）本质上是在寻找这些为了拟合少数样本而大幅偏离量化格点的“权重离群值”。  
2. **种群级曲率（Population-Level Curvature）与平均刚度**：Merullo等人分析的是**整个数据集**上的平均损失曲率（Fisher Information）。在统计平均的意义上，那些仅服务于少数记忆样本的“尖刺”方向，在海量数据的平均下会被稀释，表现为低特征值（平坦）。而服务于通用语法的权重方向，因受到所有样本的约束，表现为高特征值（刚性）。

**关键洞察**：LibOrtho实际上是在执行一种\*\*“频谱离群点检测”（Spectral Outlier Detection）\*\*。它移除的不是“平均意义上的高曲率方向”，而是“个别权重上的异常高值”。然而，这种移除存在巨大的风险：正如LibOrtho实验部分自己承认的，移除正交流导致GSM8K（数学推理）性能大幅下降 1。Merullo的研究恰好解释了这一点：算术运算（Arithmetic）和精确事实检索（Fact Retrieval）在权重空间中表现出“脆性”（Brittleness），它们像记忆化一样依赖于特定的、高精度的权重结构 5。因此，LibOrtho在切除隐私肿瘤的同时，不可避免地切除了与其几何结构相似的“精确推理”能力。

### **2.2 定理1证明过程中的数学假设脆弱性**

定理1试图证明记忆样本的梯度几乎正交于通用知识子空间。其证明过程依赖于影响函数（Influence Functions）的逆Hessian近似：$\\Delta\\theta\\approx-H^{-1}\\nabla l(z\_{i},\\theta^{\*})$ 1。

#### **2.2.1 逆Hessian向量积（iHVP）的不稳定性**

在深度神经网络特别是LLM中，直接计算或近似逆Hessian是极其困难的。2024年至2025年的多项研究 8 指出，将影响函数应用于LLM时，iHVP的估计往往存在巨大的误差，甚至符号都是错误的。这主要是因为LLM的损失景观高度非凸，且存在大量的“零特征值”方向。

* LibOrtho在证明中假设$H^{-1}$会放大平坦方向（小特征值）并抑制高曲率方向（大特征值）。虽然在线性代数上成立，但在实际的优化动力学中，优化器（如Adam）实际上是对梯度进行了预处理，使得参数更新并不完全遵循Hessian的逆方向。  
* 更严重的是，定理1隐含地假设了Hessian是对角的或者块对角的，从而忽略了不同层、不同注意力头之间的复杂**纠缠（Entanglement）**。

#### **2.2.2 对角Hessian近似的局限性：被忽略的纠缠**

LibOrtho的系统实现完全依赖于对角Hessian元素 $H\_{jj}$ 1。虽然Elsayed等人（2024）指出在某些量化任务中对角近似是有效的 10，但在涉及语义解耦的任务中，这可能是一个致命的简化。

* **纠缠的几何本质**：2025年的“几何解耦遗忘（Geometric-disentanglement Unlearning, GU）”研究 12 明确指出，遗忘与保留之间的冲突源于梯度更新在保留集子空间切平面上的投影。真正的“解耦”要求更新方向与保留集梯度的张成空间正交。  
* **LibOrtho的盲区**：如果隐私信息是通过多个权重的**非线性交互**（即非对角项）编码的，LibOrtho基于单权重曲率的筛选机制将无法识别它。这种“弥散性记忆”会漏过筛选器，残留在INT4的基础流中，导致$\\alpha=0$时的隐私泄露风险。

### **2.3 理论部分的重构建议**

为了使本文达到最佳论文的水准，作者不能回避上述矛盾，而应将其转化为论文的亮点：

1. **重新表述几何假设**：放弃“记忆=高曲率”的简单二分法。采用更精确的表述：“记忆化体现为权重空间中的高频、稀疏离群值，这些离群值在局部表现出高曲率，但在全局谱分析中可能表现为脆性结构。”  
2. **整合Merullo的发现**：明确引用Merullo等人的工作 2，承认“精确推理”（如数学）与“机械记忆”在几何结构上的相似性。这不仅解释了为什么LibOrtho会降低GSM8K的分数，反而验证了作者捕捉到了正确的几何特征——**LibOrtho成功分离了“脆性知识”（包括隐私和精确计算），留下了“鲁棒知识”（模糊推理和语法）。** 这将把实验中的缺点转化为理论上的胜利。  
3. **弱化定理1的强宣称**：将定理1从“证明”降级为“启发式推导”。承认对角近似的局限性，并讨论如果采用K-FAC（块对角）近似可能带来的理论增益（尽管计算成本过高）。

---

## **3\. 系统设计与实现：架构隔离的工程美学**

LibOrtho提出的双流架构（Dual-Stream Architecture）是本文最大的工程贡献。它将抽象的几何理论转化为具体的系统原语，这种跨越理论与系统的能力是顶级会议非常看重的特质。

### **3.1 这一设计的本质：量化即滤波器**

作者重新诠释了量化（Quantization）的意义：量化不是为了压缩体积而引入误差，而是为了**过滤特异性** 1。

* **传统视角**：$W \= W\_{quant} \+ \\text{Error}$。目标是最小化 Error 以保持性能。  
* **LibOrtho视角**：$W \= W\_{general} \+ W\_{specific}$。其中 $W\_{general}$ 是低精度的通用流形，$W\_{specific}$ 是高精度的特异性修正。

这种视角与2024年提出的SpQR（Sparse-Quantized Representation）技术 13 有异曲同工之妙，但LibOrtho将其从“压缩技术”升华为“安全架构”。SpQR保留离群值是为了恢复精度，LibOrtho将离群值隔离是为了赋予用户“遗忘的权利”。

### **3.2 运行时性能与优化细节**

系统实现部分的细节展示了作者扎实的工程功底。

1. **Warp专用融合（Warp-Dedicated Fusion）**：在GPU内核设计中，处理稀疏矩阵（FP16）和密集矩阵（INT4）的混合计算极易导致线程束的分歧（Branch Divergence）和负载不均衡。作者采用专用的Warp分别处理两股流，通过共享内存进行累加，这是一种高效的异构计算模式 1。  
2. **合并内存访问（Coalesced Memory Access）**：对于稀疏流采用CSR格式并确保合并访问，是实现1.05x加速的关键。这表明LibOrtho不仅是理论上的“隔离”，在实际部署中也是“零开销”甚至“负开销”的，极大地增加了其工业界的采用潜力。

### **3.3 架构层面的安全隐患分析**

尽管物理隔离（分离的内存缓冲区）提供了比算法遗忘更强的确定性，但系统层面仍存在攻击面，需要在修订版中深入讨论：

* **侧信道攻击（Side-Channel Attacks）**：由于稀疏流的计算模式与密集流完全不同，攻击者是否可以通过测量推理时间（Timing Attack）或功耗，来推断某个输入是否触发了大量的正交流计算？如果“敏感查询”触发了更多的稀疏计算，这本身就泄露了信息。  
* **Alpha开关的原子性**：在实际的并发服务中，如何保证 $\\alpha$ 参数的切换是原子性的？如果一个请求的一半token用了 $\\alpha=1$，另一半用了 $\\alpha=0$，会导致什么后果？

---

## **4\. 评估体系的现代化重构：告别Canary，拥抱TOFU与WMDP**

这是本文目前的软肋，也是阻碍其获得最佳论文奖的最大短板。当前的评估主要依赖“Canary提取率” 1，这一指标主要流行于2019-2022年。进入2025年，LLM遗忘与隐私评估的标准已经大幅提升。

### **4.1 Canary提取率的局限性**

LibOrtho宣称 $\\alpha=0$ 时Canary提取率降低了99.8%。这虽然令人印象深刻，但在当代安全审计看来是不足的。

* **二值化误区**：Canary提取通常是二值的（成功/失败）。但在2025年，我们更关注**概率性泄漏**。即使模型没有逐字输出Canary，它对Canary序列的困惑度（Perplexity）是否显著低于随机序列？如果是，那么通过**成员推断攻击（Membership Inference Attack, MIA）** 仍然可以确认该数据存在于训练集中 14。  
* **防御的脆弱性**：简单的微调或RLHF甚至提示词工程都可以压制逐字输出，但这并不意味着知识被移除了。架构隔离虽然更底层，但评估指标必须能捕捉到残留的统计痕迹。

### **4.2 必须纳入的2025年黄金基准**

为了证明LibOrtho不仅是“好”的，而且是“最先进”的（SOTA），必须在以下三个基准上进行全面的评估：

#### **4.2.1 TOFU (Task of Fictitious Unlearning)**

16

TOFU是目前公认的衡量遗忘效果的金标准。它构建了一个包含虚构作者及其详细信息的合成数据集。

* **为什么必须用TOFU**：TOFU提供了精确的“遗忘集”（Forget Set）和“保留集”（Retain Set），并定义了严格的指标：  
  * **遗忘质量（Forget Quality）**：模型在遗忘集上的表现是否接近于从未见过该数据的模型？这通常通过比较模型与“Retrain”模型在遗忘集上的概率分布距离（如Truth Ratio, KS Test）来衡量。  
  * **模型效用（Model Utility）**：模型在保留集上的表现是否下降？  
* **LibOrtho的测试方案**：作者需要证明，当 $\\alpha=0$ 时，模型在TOFU遗忘集上的统计行为与从未训练过该数据的模型无法区分（Indistinguishable），而不仅仅是“不输出”。

#### **4.2.2 WMDP (Weapons of Mass Destruction Proxy)**

18

WMDP关注的是消除危险知识（生物安全、网络攻击、化学武器）。这是检验LibOrtho能否用于“安全对齐”的关键。

* **测试挑战**：LibOrtho能否自动将“制造炭疽”的知识识别为高曲率离群值并隔离到正交流中？  
* **预期结果**：如果LibOrtho能证明 $\\alpha=0$ 时模型在WMDP上的准确率显著下降，同时在MMLU（通用知识）上保持稳定，这将极大地扩展该方法的应用场景——从隐私保护扩展到AI安全治理。

#### **4.2.3 MUSE (Machine Unlearning Six-Way Evaluation)**

19

MUSE提供了一个综合的六维评估框架，特别是它引入了**隐私泄露（Privacy Leakage）** 的量化指标，利用最新的MIA技术（如Min-k% Prob, LiRA）来检测隐性记忆。

* **整改要求**：作者应使用MUSE中的MIA工具包，绘制LibOrtho在 $\\alpha=0$ 时的ROC曲线。相比于单纯的准确率，展示在低假阳性率（Low FPR）下的高真阳性率（TPR）下降，将更有说服力。

### **4.3 “分级智能”与数学能力的丧失**

论文中提到的 $\\alpha=0$ 导致GSM8K（数学）性能下降 1，不应被视为缺陷，而应被重构为核心发现。

* **深度洞察**：这验证了数学推理在几何上与死记硬背具有相似性——它们都依赖于**精确的、非鲁棒的权重配置**。相比之下，语言理解和常识推理具有更高的鲁棒性（平坦最小值）。  
* **新概念提出**：作者可以借此提出\*\*“分辨率缩放智能”（Resolution-Scaled Intelligence）\*\* 的概念。 $\\alpha$ 不仅仅是隐私开关，更是“智能精度”的调节旋钮。低 $\\alpha$ 提供模糊但安全的智能（适合闲聊、创意写作），高 $\\alpha$ 提供精确但危险的智能（适合科研、编程）。这种框架将极大地提升论文的理论深度。

---

## **5\. 比较分析：LibOrtho vs. 几何解耦遗忘 (GU)**

在相关工作中，作者必须正面回应2025年提出的**几何解耦遗忘（Geometric-disentanglement Unlearning, GU）** 12。

| 特性 | LibOrtho (本文) | Geometric-disentanglement Unlearning (GU) |
| :---- | :---- | :---- |
| **方法论** | **架构隔离** (Architectural Isolation) | **算法优化** (Algorithmic Optimization) |
| **实施阶段** | 推理时 (Inference-time) | 再训练/微调时 (Re-training/Fine-tuning) |
| **正交性定义** | 静态权重分解 (基于Hessian对角线) | 动态梯度投影 (基于保留集子空间 $T\_r$) |
| **计算成本** | 极低 (一次性离线处理 \+ 零样本切换) | 高 (需要多轮梯度下降和投影计算) |
| **确定性** | **确定性** (物理切断数据流) | 概率性 (依赖优化结果) |
| **主要缺陷** | 对角近似忽略了纠缠；需维护双倍索引 | 难以扩展到超大模型；需访问原始数据 |

竞争优势分析：  
LibOrtho的最大优势在于即时性（Instantaneity）和确定性（Determinism）。GU虽然在理论上通过动态投影更精准地处理了纠缠问题，但它本质上还是一种“遗忘算法”，需要昂贵的计算。LibOrtho则提供了一种“拔掉U盘”式的物理安全感，这对法律合规（如GDPR删除权）至关重要。作者应强调这一点：LibOrtho不是让模型“学会遗忘”，而是让模型“无法回忆”。

---

## **6\. 结论与整改路线图**

结论：  
《LibOrtho》是一篇极具潜力的论文。它跳出了传统机器遗忘的窠臼，用系统架构的视角重新审视了AI安全问题。将量化误差视为隐私载体的洞察力具有图灵奖级别的潜质。然而，当前版本在理论上与最新的曲率研究存在未解释的张力，在评估上落后于2025年的SOTA基准。  
**通往最佳论文的整改路线图**：

1. **理论修正（必须）**：  
   * 明确区分“实例级高曲率”（LibOrtho的依据）与“种群级低曲率”（Merullo的发现）。  
   * 承认对角Hessian近似的局限性，并将其表述为工程权衡而非理论完美。  
2. **实验升级（关键）**：  
   * **废除**单一的Canary测试，全面引入**TOFU**和**WMDP**基准。  
   * 增加**LiRA成员推断攻击**实验，证明在概率分布层面消除了隐私痕迹。  
   * 增加与**SparseGPT**或**Wanda**（剪枝方法）的对比，证明保留离群值到正交流（而非直接剪除）对于维持 $\\alpha=1$ 时的性能是必要的。  
3. **叙事重构（加分项）**：  
   * 将数学能力的下降重塑为“脆性知识”与“鲁棒知识”几何分离的证据。  
   * 提升“架构隐私”的概念高度，将其定义为AI合规的基础设施层。

如果作者能够执行上述修改，特别是补全TOFU/WMDP的实验数据并圆融理论冲突，本文将毫无疑问成为年度最佳论文的有力竞争者，并可能开启“可信推理架构”这一全新的研究方向。

#### **Works cited**

1. libortho\_paper\_zh.pdf  
2. From Memorization to Reasoning in the Spectrum of Loss Curvature \- arXiv, accessed November 25, 2025, [https://arxiv.org/html/2510.24256v2](https://arxiv.org/html/2510.24256v2)  
3. \[2510.24256\] From Memorization to Reasoning in the Spectrum of Loss Curvature \- arXiv, accessed November 25, 2025, [https://arxiv.org/abs/2510.24256](https://arxiv.org/abs/2510.24256)  
4. From Memorization to Reasoning in the Spectrum of Loss Curvature \- Hacker News, accessed November 25, 2025, [https://news.ycombinator.com/item?id=45845800](https://news.ycombinator.com/item?id=45845800)  
5. Understanding Memorization via Loss Curvature \- Goodfire AI, accessed November 25, 2025, [https://www.goodfire.ai/research/understanding-memorization-via-loss-curvature](https://www.goodfire.ai/research/understanding-memorization-via-loss-curvature)  
6. From Memorization to Reasoning in the Spectrum of Loss Curvature \- ResearchGate, accessed November 25, 2025, [https://www.researchgate.net/publication/397006525\_From\_Memorization\_to\_Reasoning\_in\_the\_Spectrum\_of\_Loss\_Curvature](https://www.researchgate.net/publication/397006525_From_Memorization_to_Reasoning_in_the_Spectrum_of_Loss_Curvature)  
7. From Memorization to Reasoning in the Spectrum of Loss Curvature \- arXiv, accessed November 25, 2025, [https://arxiv.org/html/2510.24256v1](https://arxiv.org/html/2510.24256v1)  
8. Do Influence Functions Work on Large Language Models? \- arXiv, accessed November 25, 2025, [https://arxiv.org/html/2409.19998v2](https://arxiv.org/html/2409.19998v2)  
9. Scalable Multi-Stage Influence Function for Large Language Models via Eigenvalue-Corrected Kronecker-Factored Parameterization \- arXiv, accessed November 25, 2025, [https://arxiv.org/html/2505.05017v1](https://arxiv.org/html/2505.05017v1)  
10. Revisiting Scalable Hessian Diagonal Approximations for Applications in Reinforcement Learning, accessed November 25, 2025, [https://proceedings.mlr.press/v235/elsayed24a.html](https://proceedings.mlr.press/v235/elsayed24a.html)  
11. Contents \- arXiv, accessed November 25, 2025, [https://arxiv.org/html/2504.04520v1](https://arxiv.org/html/2504.04520v1)  
12. \[2511.17100\] Geometric-Disentangelment Unlearning \- arXiv, accessed November 25, 2025, [https://arxiv.org/abs/2511.17100](https://arxiv.org/abs/2511.17100)  
13. SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression | Request PDF \- ResearchGate, accessed November 25, 2025, [https://www.researchgate.net/publication/371311412\_SpQR\_A\_Sparse-Quantized\_Representation\_for\_Near-Lossless\_LLM\_Weight\_Compression](https://www.researchgate.net/publication/371311412_SpQR_A_Sparse-Quantized_Representation_for_Near-Lossless_LLM_Weight_Compression)  
14. OPTIFLUENCE: SCALABLE AND PRINCIPLED DESIGN OF PRIVACY CANARIES \- OpenReview, accessed November 25, 2025, [https://openreview.net/pdf/207964cb110ca62e0cacb6364efdad71af260cd4.pdf](https://openreview.net/pdf/207964cb110ca62e0cacb6364efdad71af260cd4.pdf)  
15. SCALABLE EXTRACTION OF TRAINING DATA FROM ALIGNED, PRODUCTION LANGUAGE MODELS \- ICLR Proceedings, accessed November 25, 2025, [https://proceedings.iclr.cc/paper\_files/paper/2025/file/cce0e917b050208170151f77b497fc71-Paper-Conference.pdf](https://proceedings.iclr.cc/paper_files/paper/2025/file/cce0e917b050208170151f77b497fc71-Paper-Conference.pdf)  
16. Geometric-disentanglement Unlearning \- arXiv, accessed November 25, 2025, [https://arxiv.org/html/2511.17100v1](https://arxiv.org/html/2511.17100v1)  
17. \[2401.06121\] TOFU: A Task of Fictitious Unlearning for LLMs \- arXiv, accessed November 25, 2025, [https://arxiv.org/abs/2401.06121](https://arxiv.org/abs/2401.06121)  
18. WMDP Benchmark, accessed November 25, 2025, [https://www.wmdp.ai/](https://www.wmdp.ai/)  
19. muse-bench/MUSE-News · Datasets at Hugging Face, accessed November 25, 2025, [https://huggingface.co/datasets/muse-bench/MUSE-News](https://huggingface.co/datasets/muse-bench/MUSE-News)  
20. OpenUnlearning: Accelerating LLM Unlearning via Unified Benchmarking of Methods and Metrics \- arXiv, accessed November 25, 2025, [https://arxiv.org/pdf/2506.12618?](https://arxiv.org/pdf/2506.12618)  
21. GEOMETRIC-DISENTANGLEMENT UNLEARNING \- OpenReview, accessed November 25, 2025, [https://openreview.net/pdf?id=WLpNPSo20n](https://openreview.net/pdf?id=WLpNPSo20n)